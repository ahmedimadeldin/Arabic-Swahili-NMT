{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "hoZOYLhJg7Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentencepiece -q\n",
        "! pip install wandb\n",
        "import numpy\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "import wandb\n",
        "\n",
        "wandb.login()\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.enabled = False\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "set_seed(7)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir checkpoint"
      ],
      "metadata": {
        "id": "Zr_4rVKGjrBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYmIDW5fN7yS"
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq -q\n",
        "%cd fairseq\n",
        "!pip uninstall numpy -q -y\n",
        "!pip install wandb -q\n",
        "!pip install --editable ./ -q\n",
        "%cd ..\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UldcvGCPOEbv"
      },
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSA3MTlTOOWq"
      },
      "source": [
        "!wget -qq \"https://dl.fbaipublicfiles.com/m2m_100/spm.128k.model\"\n",
        "!wget -qq \"https://dl.fbaipublicfiles.com/m2m_100/data_dict.128k.txt\"\n",
        "!wget -qq \"https://dl.fbaipublicfiles.com/m2m_100/model_dict.128k.txt\"\n",
        "!wget -qq \"https://dl.fbaipublicfiles.com/m2m_100/language_pairs_small_models.txt\"\n",
        "!wget     \"https://dl.fbaipublicfiles.com/m2m_100/418M_last_checkpoint.pt\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "G7dKphFchJDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/DATA.zip\n",
        "!unzip /content/final_split.zip"
      ],
      "metadata": {
        "id": "hMzE13yKxbHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/final_training_set.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zr_SWTJ1xeN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare the training set\n",
        "PATH_TO_DATASET = \"/content\"  #Where you stored the dataset\n",
        "\n",
        "train = pd.read_csv(os.path.join(PATH_TO_DATASET, \"final_training_set.csv\"))\n",
        "train.columns = [\"Swahili\",\"Arabic\"]\n",
        "\n",
        "#Remove any possible duplicates\n",
        "train = train.drop_duplicates(subset=[\"Arabic\", \"Swahili\"])\n",
        "\n",
        "#Lowercase and remove trailing spaces\n",
        "train[\"Arabic\"] = train.apply(lambda x: (x.Arabic).strip().lower(), axis=1)\n",
        "train[\"Swahili\"] = train.Swahili.apply(lambda x: x.lower())\n",
        "\n",
        "train = train[[\"Arabic\", \"Swahili\" ]]\n",
        "train.columns = [\"input_text\", \"target_text\"]\n",
        "\n",
        "#prepare the test set\n",
        "validation = pd.read_csv(os.path.join(PATH_TO_DATASET, \"final_test_set.csv\"))\n",
        "validation.columns = [\"Swahili\",\"Arabic\"]\n",
        "#Remove any possible duplicates\n",
        "validation = validation.drop_duplicates(subset=[\"Arabic\", \"Swahili\"])\n",
        "\n",
        "#Lowercase and remove trailing spaces\n",
        "validation[\"Arabic\"] = validation.apply(lambda x: (x.Arabic).strip().lower(), axis=1)\n",
        "validation[\"Swahili\"] = validation.Swahili.apply(lambda x: x.lower())\n",
        "\n",
        "validation = validation[[\"Arabic\", \"Swahili\"]]\n",
        "validation.columns = [\"input_text\", \"target_text\"]\n",
        "\n",
        "\n",
        "# train.head()\n",
        "# validation.head()"
      ],
      "metadata": {
        "id": "J8t5hmEfxnme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APIKtxs1O7ix"
      },
      "source": [
        "# For the training set\n",
        "train_txt = \"\\n\".join(train.input_text.values.tolist())\n",
        "file = open(\"Arabic_txt_train.txt\", \"w\")\n",
        "\n",
        "file.write(train_txt)\n",
        "file.close()\n",
        "\n",
        "\n",
        "train_target_txt = \"\\n\".join(train.target_text.values.tolist())\n",
        "file = open(\"Swahili_txt_train.txt\", \"w\")\n",
        "\n",
        "file.write(train_target_txt)\n",
        "file.close()\n",
        "\n",
        "\n",
        "# For the validation set\n",
        "validation_txt = \"\\n\".join(validation.input_text.values.tolist())\n",
        "file = open(\"Arabic_txt_validation.txt\", \"w\")\n",
        "\n",
        "file.write(validation_txt)\n",
        "file.close()\n",
        "\n",
        "\n",
        "validation_target_txt = \"\\n\".join(validation.target_text.values.tolist())\n",
        "file = open(\"Swahili_txt_validation.txt\", \"w\")\n",
        "\n",
        "file.write(validation_target_txt)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BPE Tokenization\n",
        "!python fairseq/scripts/spm_encode.py \\\n",
        "        --model spm.128k.model \\\n",
        "        --output_format=piece \\\n",
        "        --inputs=Arabic_txt_train.txt \\\n",
        "        --outputs=train.ar\n",
        "\n",
        "!python fairseq/scripts/spm_encode.py \\\n",
        "        --model spm.128k.model \\\n",
        "        --output_format=piece \\\n",
        "        --inputs=Swahili_txt_train.txt \\\n",
        "        --outputs=train.sw\n",
        "\n",
        "!python fairseq/scripts/spm_encode.py \\\n",
        "        --model spm.128k.model \\\n",
        "        --output_format=piece \\\n",
        "        --inputs=Arabic_txt_validation.txt \\\n",
        "        --outputs=val.ar\n",
        "!python fairseq/scripts/spm_encode.py \\\n",
        "        --model spm.128k.model \\\n",
        "        --output_format=piece \\\n",
        "        --inputs=Swahili_txt_validation.txt \\\n",
        "        --outputs=val.sw"
      ],
      "metadata": {
        "id": "Yi_5Go5UeF1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! echo $PYTHONPATH\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n",
        "\n",
        "! echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40ZLJMvT0oZL",
        "outputId": "121d8d2f-0164-48d9-92ab-ab9ce36d2607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/env/python:/content/fairseq/\n",
            "/env/python:/content/fairseq/:/content/fairseq/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#next is preparing the data to be fed to the transformer"
      ],
      "metadata": {
        "id": "8e2oFK4qjKJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH_Lh7WFPGZO",
        "outputId": "aa16a690-b4d8-479b-fe4e-6417e357d5b0"
      },
      "source": [
        "!fairseq-preprocess \\\n",
        "    --source-lang ar --target-lang sw \\\n",
        "    --trainpref train \\\n",
        "    --validpref val \\\n",
        "    --thresholdsrc 0 --thresholdtgt 0 \\\n",
        "    --destdir data_bin \\\n",
        "    --srcdict model_dict.128k.txt --tgtdict model_dict.128k.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-07 23:55:58.974435: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-07 23:55:58.974512: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-07 23:55:58.974550: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-07 23:55:58.983243: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-07 23:56:00.815430: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX\n",
            "INFO:fairseq_cli.preprocess:Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', simul_type=None, scoring='bleu', task='translation', source_lang='ar', target_lang='sw', trainpref='train', validpref='val', testpref=None, align_suffix=None, destdir='data_bin', thresholdtgt=0, thresholdsrc=0, tgtdict='model_dict.128k.txt', srcdict='model_dict.128k.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=1, dict_only=False)\n",
            "INFO:fairseq_cli.preprocess:[ar] Dictionary: 128112 types\n",
            "INFO:fairseq_cli.preprocess:[ar] train.ar: 29531 sents, 1026491 tokens, 0.00127% replaced (by <unk>)\n",
            "INFO:fairseq_cli.preprocess:[ar] Dictionary: 128112 types\n",
            "INFO:fairseq_cli.preprocess:[ar] val.ar: 3281 sents, 112827 tokens, 0.0% replaced (by <unk>)\n",
            "INFO:fairseq_cli.preprocess:[sw] Dictionary: 128112 types\n",
            "INFO:fairseq_cli.preprocess:[sw] train.sw: 29531 sents, 1123711 tokens, 0.00116% replaced (by <unk>)\n",
            "INFO:fairseq_cli.preprocess:[sw] Dictionary: 128112 types\n",
            "INFO:fairseq_cli.preprocess:[sw] val.sw: 3281 sents, 123931 tokens, 0.000807% replaced (by <unk>)\n",
            "INFO:fairseq_cli.preprocess:Wrote preprocessed data to data_bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "The M2M100 model was finetuned starting with the initial downloaded checkpoint : 418M_last_checkpoint.pt"
      ],
      "metadata": {
        "id": "hvm_M4vCmAwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-train data_bin \\\n",
        "  --finetune-from-model \"/content/418M_last_checkpoint.pt\"\\\n",
        "  --save-dir '/content/checkpoint' \\\n",
        "  --task translation_multi_simple_epoch \\\n",
        "  --encoder-normalize-before \\\n",
        "  --lang-pairs 'ar-sw' \\\n",
        "  --batch-size 16 \\\n",
        "  --decoder-normalize-before \\\n",
        "  --encoder-langtok src \\\n",
        "  --decoder-langtok \\\n",
        "  --criterion cross_entropy \\\n",
        "  --optimizer adafactor \\\n",
        "  --lr-scheduler cosine \\\n",
        "  --lr 3e-05 \\\n",
        "  --max-update 40000 \\\n",
        "  --update-freq 100 \\\n",
        "  --save-interval 1 \\\n",
        "  --save-interval-updates 5000 \\\n",
        "  --keep-interval-updates 10 \\\n",
        "  --no-epoch-checkpoints \\\n",
        "  --log-format simple \\\n",
        "  --log-interval 2 \\\n",
        "  --patience 15 \\\n",
        "  --arch transformer_wmt_en_de_big \\\n",
        "  --encoder-layers 12 \\\n",
        "  --decoder-layers 12 \\\n",
        "  --share-decoder-input-output-embed \\\n",
        "  --share-all-embeddings \\\n",
        "  --ddp-backend no_c10d \\\n",
        "  --max-epoch 15 \\\n",
        "  --wandb-project \"M2M Arabic To Swahili FINAL \" \\\n",
        "  # --save-interval 5 \\\n",
        "  # --keep-last-epochs 5 \\\n",
        "  # --best-checkpoint-metric loss \\\n",
        "  # --maximize-best-checkpoint-metric \\\n",
        "  # --save-dir '/content/drive/MyDrive/checkpoints'"
      ],
      "metadata": {
        "id": "xWhEMFCYec4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation & Calculating BLEU Score"
      ],
      "metadata": {
        "id": "pQUcrY8rmdxx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoMhPbVXh_y2"
      },
      "source": [
        "# !rm -rf data_bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSTqGqwiQoa7"
      },
      "source": [
        "!fairseq-preprocess \\\n",
        "    --source-lang ar --target-lang sw \\\n",
        "    --testpref val \\\n",
        "    --thresholdsrc 0 --thresholdtgt 0 \\\n",
        "    --destdir data_bin \\\n",
        "    --srcdict data_dict.128k.txt --tgtdict data_dict.128k.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh7O9DsYPMkR"
      },
      "source": [
        "#for calculating BLEU score with BPE\n",
        "!fairseq-generate \"data_bin/\"  --batch-size 32 \\\n",
        "      --path \"/content/checkpoint/checkpoint_best.pt\" \\\n",
        "      --fixed-dictionary model_dict.128k.txt \\\n",
        "      -s ar -t sw \\\n",
        "      --beam 5 \\\n",
        "      --task translation_multi_simple_epoch \\\n",
        "      --lang-pairs language_pairs_small_models.txt \\\n",
        "      --decoder-langtok \\\n",
        "      --encoder-langtok src \\\n",
        "      --gen-subset test > m2m_Results.txt\n",
        "#for calculating BLEU score without BPE\n",
        "# !fairseq-generate \"data_bin/\"  --batch-size 32 \\\n",
        "#       --path \"/content/checkpoint/checkpoint_last.pt\" \\\n",
        "#       --fixed-dictionary model_dict.128k.txt \\\n",
        "#       -s ar -t sw \\\n",
        "#       --beam 5 \\\n",
        "#       --task translation_multi_simple_epoch \\\n",
        "#       --lang-pairs language_pairs_small_models.txt \\\n",
        "#       --remove-bpe 'sentencepiece' \\\n",
        "#       --decoder-langtok \\\n",
        "#       --encoder-langtok src \\\n",
        "#       --gen-subset test > m2m_Results.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/m2m_Results.txt\") as f:\n",
        "  text = f.read()\n",
        "  text = text.split()\n",
        "  print(\" \".join(text[-8:-5]))"
      ],
      "metadata": {
        "id": "mIfRc3zFxo4F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}